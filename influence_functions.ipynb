{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6Pp+dha1ZKp/qGwxR9i4U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nebulous05/influence-functions-pytorch/blob/main/influence_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "NKBl5oYXwcki"
      },
      "outputs": [],
      "source": [
        "### PROCEDURE ###\n",
        "\n",
        "# Step 1: Train a model on the 10-class MNIST dataset\n",
        "# Step 2: Arbitrarily select a wrongly-classified test point, z_test\n",
        "# Step 3: Compute the influence I_up,loss(z, z_test) for every training point z\n",
        "# Step 4: Select the 500 training points with the largest |I_up,loss(z, z_test)|\n",
        "# Step 5: Compute the actual change in test loss after removing the point and\n",
        "#         retraining for each of the 500 points\n",
        "# Step 6: Plot -1/n (I_up,loss(z, z_test)) vs. actual change in test loss for\n",
        "#         each of the 500 points"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Arbitrarily select a wrongly-classified test point, z_test"
      ],
      "metadata": {
        "id": "RaCfGKqRwjI2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.autograd import grad\n",
        "from torch.autograd.functional import hvp\n",
        "from torch.utils.data import Subset"
      ],
      "metadata": {
        "id": "7F1A0iOpwm8o"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data is torch.FloatTensor; shape = (1, 28, 28)\n",
        "# load train data: 60,000 samples\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "#loading test data: 10,000 samples\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmn3n0bpwpwI",
        "outputId": "d0836188-cb2c-44c9-d823-31dda9c2e005"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 30963544.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 3468452.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 8610454.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 7810794.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_item(index, dataset='train'):\n",
        "    ''' returns a pair (image_tensor, label_int) '''\n",
        "    if dataset == 'train':\n",
        "        return train_dataset[index]\n",
        "    elif dataset == 'test':\n",
        "        return test_dataset[index]\n",
        "\n",
        "def show_image(index, dataset='train'):\n",
        "    ''' show an image with matplotlib '''\n",
        "    if dataset == 'train':\n",
        "        img = train_dataset[index][0].numpy().reshape(28, 28)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.show()\n",
        "    elif dataset == 'test':\n",
        "        img = test_dataset[index][0].numpy().reshape(28, 28)\n",
        "        plt.imshow(img, cmap='gray')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "sISqw3Bjwve_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load train and test data samples into dataloader\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "Pp6y3-vJw2av"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom module for logistic regression\n",
        "class LRModel(nn.Module):\n",
        "    def __init__(self, n_inputs, n_outputs):\n",
        "        super(LRModel, self).__init__()\n",
        "        self.linear = nn.Linear(n_inputs, n_outputs)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "14I5FLzyw5nX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate the model\n",
        "n_inputs = 28*28\n",
        "n_outputs = 10\n",
        "model = LRModel(n_inputs, n_outputs)\n",
        "model.load_state_dict(torch.load('model_weights.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH-9cY1Fw706",
        "outputId": "a8eb910d-836c-415f-d22e-f15f85a7e52c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-ac56d928a54d>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('model_weights.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_misclassified_indices(model=model, test_dataset=test_dataset):\n",
        "  ''' returns a list of indices of all incorrectly labeled test points '''\n",
        "  model.eval()\n",
        "  indices = []\n",
        "  for i in range(len(test_dataset)):\n",
        "    image, label = get_item(i, dataset='test')\n",
        "    image = image.view(-1, 28*28)\n",
        "    with torch.no_grad():\n",
        "      y_pred = model(image)\n",
        "      _, predicted = torch.max(y_pred.data, 1)\n",
        "      if predicted != label:\n",
        "        indices.append(i)\n",
        "  return indices\n",
        "\n",
        "mislabeled_indices = find_misclassified_indices()"
      ],
      "metadata": {
        "id": "x7gVRrERxJqu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(random.choice(mislabeled_indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSFnT8fJQBkG",
        "outputId": "6403b671-28bf-4d16-8500-df304b630596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "image, label = get_item(3476, dataset='test')\n",
        "y_pred = model(image.view(-1, 28*28))\n",
        "_, predicted = torch.max(y_pred.data, 1)\n",
        "\n",
        "# z_test\n",
        "z_test = image.view(-1, 28*28)\n",
        "z_test_label = torch.tensor([test_dataset[3476][1]])\n",
        "\n",
        "print(\"predicted value: \", predicted)\n",
        "print(\"actual value: \", z_test_label)\n",
        "show_image(3476, dataset='test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "_Z6mEJy2QvBt",
        "outputId": "f6aab107-0a4a-4750-8fb2-92cfadb9ab8f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted value:  tensor([8])\n",
            "actual value:  tensor([3])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Compute the influence I_up,loss(z, z_test) for every training point z"
      ],
      "metadata": {
        "id": "Yy1HW-rgQxa7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get gradient of loss wrt params to kick off LiSSA\n",
        "def compute_v(model, z_test, z_test_label, loss_fn):\n",
        "    model.zero_grad()\n",
        "    output = model(z_test)\n",
        "    loss = loss_fn(output, z_test_label)\n",
        "\n",
        "    v = grad(loss, model.parameters())\n",
        "    return v\n",
        "\n",
        "# returns list of torch tensors containing product of Hessian and v.\n",
        "def hvp(y, w, v):\n",
        "    # First backprop: Compute the gradient of y with respect to w\n",
        "    first_grads = grad(y, w, retain_graph=True, create_graph=True)\n",
        "\n",
        "    # Elementwise products\n",
        "    elemwise_products = 0\n",
        "    for grad_elem, v_elem in zip(first_grads, v):\n",
        "        elemwise_products += torch.sum(grad_elem * v_elem)\n",
        "\n",
        "    # Second backprop: Compute gradient of elementwise product with respect to w\n",
        "    return_grads = grad(elemwise_products, w, create_graph=True)\n",
        "\n",
        "    return return_grads\n",
        "\n",
        "# Precompute s_test using stochastic estimation, now using a mini-batch from the training data\n",
        "def compute_s_test(model, z_test, v, loss_fn, scale=25, recursion_depth=5000, damping=0, batch_size=1, num_samples=10):\n",
        "    model.eval()\n",
        "    s_test = None\n",
        "\n",
        "    for j in range(num_samples):\n",
        "        print(\"Beginning of repeat #\", j+1)\n",
        "        h_estimate = v  # Start with the gradient of z_test\n",
        "\n",
        "        for i in range(recursion_depth):\n",
        "            # Sample a random mini-batch from the training data\n",
        "            batch_indices = random.sample(range(len(train_dataset)), batch_size)\n",
        "            train_batch = [train_dataset[i] for i in batch_indices]\n",
        "            train_batch_inputs = torch.stack([x[0].view(-1, 28*28).squeeze() for x in train_batch])\n",
        "            train_batch_labels = torch.tensor([x[1] for x in train_batch])\n",
        "\n",
        "            model.zero_grad()\n",
        "            output = model(train_batch_inputs)\n",
        "            loss = loss_fn(output, train_batch_labels)\n",
        "\n",
        "            # Compute the Hessian-vector product\n",
        "            hv = hvp(loss, list(model.parameters()), h_estimate)\n",
        "\n",
        "            # Recursively update h_estimate\n",
        "            h_estimate = [\n",
        "                _v + (1 - damping) * _h_e - _hv / scale\n",
        "                for _v, _h_e, _hv in zip(v, h_estimate, hv)\n",
        "            ]\n",
        "\n",
        "            # Detach to prevent graph retention and memory buildup\n",
        "            h_estimate = [h.detach() for h in h_estimate]\n",
        "\n",
        "            if i%1000 == 0:\n",
        "              print(\"Completed \", i, \" iterations\")\n",
        "\n",
        "        if s_test is None:\n",
        "            s_test = h_estimate\n",
        "        else:\n",
        "            s_test = [s + h for s, h in zip(s_test, h_estimate)]\n",
        "\n",
        "    # Average over the number of samples\n",
        "    s_test = [s / num_samples for s in s_test]\n",
        "\n",
        "    return s_test"
      ],
      "metadata": {
        "id": "e3zKOynsS9VI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = compute_v(model, z_test, z_test_label, loss_fn)\n",
        "s_test = compute_s_test(model, z_test, v, loss_fn)"
      ],
      "metadata": {
        "id": "Y0sssOok_pz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0cc4da0-dd37-4a9e-b297-52373644938a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning of repeat # 1\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Beginning of repeat # 2\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Beginning of repeat # 3\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Beginning of repeat # 4\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Beginning of repeat # 5\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Beginning of repeat # 6\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Beginning of repeat # 7\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Beginning of repeat # 8\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Beginning of repeat # 9\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Beginning of repeat # 10\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# returns a list where the ith index is the value of the influence for index i\n",
        "# of the training set\n",
        "def compute_influence(model, train_dataset, s_test, loss_fn):\n",
        "    model.eval()\n",
        "\n",
        "    # List to store influence scores for each training point\n",
        "    influence_scores = []\n",
        "\n",
        "    # Loop over each data point in the training set\n",
        "    for z in train_dataset:\n",
        "        # Extract input and label from training dataset point\n",
        "        z_input = z[0].view(-1, 28*28)\n",
        "        z_label = torch.tensor([z[1]])\n",
        "\n",
        "        # Compute the gradient of the loss of the training point wrt the model parameters (v)\n",
        "        v = compute_v(model, z_input, z_label, loss_fn)\n",
        "\n",
        "        # Now compute the dot product between s_test and v\n",
        "        influence = 0\n",
        "        for s, v_i in zip(s_test, v):\n",
        "            influence += torch.sum(s * v_i)\n",
        "\n",
        "        # Store the negative of the influence as we want -s_test . v\n",
        "        influence_scores.append(-influence.item())  # Append scalar value to the list\n",
        "\n",
        "    return influence_scores\n"
      ],
      "metadata": {
        "id": "CCklO7L_ygrT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "influence_scores = compute_influence(model, train_dataset, s_test, loss_fn)"
      ],
      "metadata": {
        "id": "SBPv4i2e7KzV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_top_influential_points(influence_scores, top_n=500):\n",
        "    # Create a dictionary mapping index i to the influence score\n",
        "    influence_dict = {i: influence_scores[i] for i in range(len(influence_scores))}\n",
        "\n",
        "    # Sort the dictionary by the absolute value of the influence scores in descending order\n",
        "    sorted_influences = sorted(influence_dict.items(), key=lambda item: abs(item[1]), reverse=True)\n",
        "\n",
        "    # Select the top N most influential points\n",
        "    top_influential_dict = dict(sorted_influences[:top_n])\n",
        "\n",
        "    return top_influential_dict"
      ],
      "metadata": {
        "id": "-hOFbfSK_DXb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_influential_dict = select_top_influential_points(influence_scores)\n",
        "print(len(top_influential_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzKPHqXO_ErD",
        "outputId": "34dff903-e2d0-43a3-b4c4-c871bfb29262"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_influential_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LsBPhMK_vz2",
        "outputId": "fd5a1d73-0348-4e09-ba94-b2aec41c4f07"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{27838: -1888.504638671875, 27795: -1807.0599365234375, 34140: -1707.6995849609375, 8708: -1669.60693359375, 48806: -1505.1011962890625, 26305: -1502.1468505859375, 3358: -1496.95361328125, 47207: -1468.4534912109375, 21182: -1443.5009765625, 25266: -1427.6785888671875, 49968: -1421.75048828125, 6398: -1418.408935546875, 25346: -1411.9080810546875, 35498: -1403.72509765625, 13656: -1382.3291015625, 48922: -1369.3443603515625, 18007: -1356.2271728515625, 9255: -1349.0557861328125, 58379: -1343.884033203125, 32031: -1323.140869140625, 33371: -1322.9954833984375, 15869: -1318.0118408203125, 52740: -1317.9273681640625, 49018: -1317.3077392578125, 48930: -1308.36962890625, 12546: -1300.30419921875, 56305: -1286.64892578125, 29670: -1275.9942626953125, 13488: -1266.1116943359375, 34846: -1258.08935546875, 33763: -1255.1480712890625, 40620: -1247.1812744140625, 22404: -1245.2318115234375, 24205: -1240.5933837890625, 16019: -1238.83740234375, 22459: -1233.349609375, 46329: -1231.065673828125, 37908: -1229.8917236328125, 40404: -1225.2442626953125, 2252: -1213.465576171875, 23888: -1213.2265625, 25328: -1211.2166748046875, 55488: -1209.4642333984375, 37260: -1206.5826416015625, 26194: -1203.467529296875, 30084: -1184.63720703125, 24111: -1168.7568359375, 43140: -1166.225341796875, 52972: -1155.6536865234375, 26399: -1151.9149169921875, 47930: -1143.02783203125, 53246: -1139.2027587890625, 19620: -1139.0223388671875, 28299: -1134.330810546875, 9089: -1131.04443359375, 13778: -1123.379150390625, 38752: -1105.5103759765625, 46296: -1104.62158203125, 24772: -1098.4742431640625, 28444: -1095.17431640625, 53619: -1086.293701171875, 37896: -1082.66845703125, 58086: -1082.4296875, 43256: -1073.7259521484375, 2042: -1067.3453369140625, 33729: -1064.467041015625, 3318: -1054.1370849609375, 53722: -1053.588134765625, 40298: -1053.2642822265625, 6827: -1048.212890625, 54694: -1045.4888916015625, 54402: -1044.4365234375, 52922: -1043.202880859375, 48904: -1034.7340087890625, 19016: -1031.5594482421875, 21468: -1030.180908203125, 48798: -1029.275390625, 18240: -1020.2787475585938, 35568: -1017.308837890625, 46592: -1016.6007690429688, 29936: -1004.56494140625, 58324: -1001.8878784179688, 51998: -1000.2705078125, 7383: -993.8216552734375, 15945: -993.3242797851562, 1436: -988.6651611328125, 1836: -986.7997436523438, 51038: -986.3119506835938, 11524: -982.2821655273438, 18227: -980.4658813476562, 42994: -978.3514404296875, 43747: -977.810546875, 24870: -975.1334228515625, 46442: -968.7830810546875, 52378: -968.1582641601562, 574: -963.2669067382812, 4866: 960.4984130859375, 44034: -959.892333984375, 40892: -958.544189453125, 3844: -957.0462646484375, 42097: -955.7118530273438, 36093: -952.3883056640625, 21660: -949.0776977539062, 16003: -948.4683837890625, 12109: -946.9569702148438, 5798: -945.0230712890625, 54898: -943.6790161132812, 42024: -942.3417358398438, 42804: -941.6033935546875, 50554: -941.2656860351562, 58421: -940.1708374023438, 52692: -940.0712890625, 21539: -938.8892822265625, 33745: -934.9721069335938, 5616: -934.7824096679688, 14686: -933.616943359375, 6016: -931.2406005859375, 43654: -929.5641479492188, 32850: -925.588134765625, 15980: -924.1851806640625, 19834: -921.1506958007812, 32656: -920.3067626953125, 28026: -914.7835083007812, 33837: -913.3765258789062, 13576: -900.6649169921875, 4471: 898.9053955078125, 25861: -898.8819580078125, 54398: -898.2099609375, 41773: -897.5350341796875, 13376: -893.15771484375, 46051: -889.5715942382812, 55715: -887.1736450195312, 40202: -886.854248046875, 58298: -884.7030029296875, 33875: -883.4357299804688, 42264: -881.3460693359375, 46480: -879.5021362304688, 51798: -876.0582885742188, 25883: -874.1414794921875, 23165: -872.6290893554688, 42220: -872.1268920898438, 6658: -870.7391357421875, 55694: -865.37841796875, 49946: -861.8961181640625, 47946: -857.0408935546875, 13212: -855.8905029296875, 50000: -850.728759765625, 30072: -847.44970703125, 26403: -845.4120483398438, 25034: -843.8180541992188, 19238: -843.692626953125, 39820: -843.0838623046875, 47352: -842.2960815429688, 9293: -841.394775390625, 17354: -841.0321655273438, 9696: -840.7355346679688, 16510: -839.283203125, 48788: -838.8849487304688, 4742: -838.4752197265625, 11951: -836.4508056640625, 29958: -833.6973876953125, 22468: -832.2135620117188, 22674: -828.4725341796875, 856: -826.3453979492188, 36488: -825.9312744140625, 34828: 824.6895751953125, 10450: -821.7698974609375, 23986: -819.437744140625, 52101: -813.4290161132812, 25941: -811.3660888671875, 46918: -811.2769775390625, 22172: -810.8035278320312, 35969: -810.7601928710938, 20708: -808.2440185546875, 48642: -807.70458984375, 23320: -805.4674072265625, 21726: -805.2306518554688, 3435: -804.0042724609375, 55628: -802.7771606445312, 53554: -795.5460205078125, 15008: -795.3494873046875, 28032: -794.995849609375, 47361: -788.7998046875, 5702: -787.178466796875, 25809: -786.7674560546875, 878: -786.1448364257812, 23076: -785.9445190429688, 48065: -784.7548828125, 55485: -783.5355834960938, 4328: -781.3153686523438, 34204: -779.5343627929688, 5148: -779.051025390625, 54199: -777.5314331054688, 52446: -777.2813720703125, 17442: -774.3500366210938, 34368: -773.0016479492188, 3048: -772.0067749023438, 38990: -771.8365478515625, 24835: -771.819091796875, 17409: -771.6910400390625, 31488: -771.6405029296875, 23157: -771.1261596679688, 29800: -769.3104248046875, 38892: -768.8880615234375, 6362: -767.5252075195312, 20252: -767.5245971679688, 27960: -763.7554931640625, 3824: -762.9581298828125, 28916: -762.4340209960938, 6342: -762.2328491210938, 48465: -760.8926391601562, 56204: -760.04931640625, 36815: -758.2274169921875, 9602: -757.1396484375, 9078: -756.8399658203125, 21610: -756.1414794921875, 33845: -754.3069458007812, 4257: -753.49365234375, 38116: -752.35009765625, 19976: -748.4221801757812, 34548: -748.226806640625, 44837: -747.64697265625, 1348: -747.6249389648438, 5127: -747.471435546875, 39445: -745.573486328125, 11554: -745.2314453125, 53591: -745.0692138671875, 10466: -742.5702514648438, 17646: -741.0365600585938, 54530: -740.466064453125, 47157: -740.2642211914062, 41781: -738.0593872070312, 23482: -737.968017578125, 19579: -737.21630859375, 42178: -736.451904296875, 13750: -736.43310546875, 33760: -735.9945068359375, 35814: -735.9486083984375, 33331: -732.65966796875, 15474: -732.6174926757812, 6711: -732.1388549804688, 32106: 730.9004516601562, 44240: 730.186279296875, 32490: -729.7162475585938, 29791: -728.1134033203125, 56616: -727.4323120117188, 37309: 727.0943603515625, 48300: -725.6478881835938, 40087: 725.3546142578125, 4638: -725.123046875, 37188: -723.9132080078125, 7295: -723.0830078125, 49948: -722.1473999023438, 42951: -720.334716796875, 39317: -720.021240234375, 24906: -719.2040405273438, 44058: -719.0562133789062, 10518: -718.8280029296875, 13906: -716.5050048828125, 540: -715.7562255859375, 18960: -714.9126586914062, 50195: -713.4197998046875, 8794: -712.5640869140625, 19883: -708.1205444335938, 36957: -707.733154296875, 35208: -707.6973876953125, 38053: -707.553466796875, 10762: -706.3942260742188, 30398: -704.5755615234375, 10214: -703.9837036132812, 51675: -703.9356079101562, 55179: -703.0309448242188, 56134: -702.6558837890625, 13294: -702.5661010742188, 30974: -698.686279296875, 18039: -697.0568237304688, 19855: -696.3778686523438, 56645: 695.7880859375, 44: -695.4916381835938, 55353: -695.0852661132812, 4988: -693.3132934570312, 49810: -693.117431640625, 22182: -692.3031005859375, 58654: -687.5148315429688, 35022: -686.7582397460938, 37555: 685.8716430664062, 44799: -684.4546508789062, 59598: -684.053955078125, 27625: -683.284423828125, 16530: -682.4362182617188, 21950: -682.0617065429688, 26048: -681.2058715820312, 30254: -679.1317138671875, 43476: -678.642822265625, 22536: -678.0906982421875, 41704: -673.0560913085938, 17460: -672.5835571289062, 15937: -672.3744506835938, 50378: -671.08740234375, 45814: -670.6883544921875, 52753: 670.4714965820312, 30740: -670.1572265625, 37065: -670.0905151367188, 22304: 669.10009765625, 46379: -668.6581420898438, 32764: -667.8780517578125, 13109: 666.7344970703125, 52027: -664.7855834960938, 20220: 664.6279907226562, 3810: -663.2339477539062, 24099: -662.9655151367188, 459: -660.6070556640625, 29610: -658.137939453125, 13745: -658.0648193359375, 39565: -657.9822387695312, 21306: -657.6338500976562, 33357: -657.2982788085938, 21930: 654.868896484375, 12086: -654.5623168945312, 5252: -654.4276733398438, 1862: -654.0047607421875, 16071: -653.5364379882812, 45015: -653.4732055664062, 46736: -652.2821655273438, 55509: -650.40576171875, 18390: 646.7415161132812, 56288: -646.5806884765625, 18285: -645.7579956054688, 3462: -644.7767333984375, 47749: 643.8340454101562, 55796: -642.9293823242188, 24784: -642.81396484375, 21866: -642.6780395507812, 23287: -640.6168212890625, 22598: -637.1558227539062, 34170: -636.8272705078125, 6754: -633.41796875, 24145: -633.1966552734375, 3174: -632.6005859375, 17328: -632.0411376953125, 37439: 631.7968139648438, 25915: -630.95556640625, 41820: -629.3169555664062, 24326: -629.262939453125, 50950: -627.9871826171875, 50260: -627.1954345703125, 53758: 627.0275268554688, 31952: -625.5419311523438, 26998: -625.1171875, 41822: 624.9667358398438, 37996: -624.2456665039062, 44146: -623.4735717773438, 34646: 623.2966918945312, 48998: -621.4451904296875, 7660: -620.63818359375, 43090: -620.5015258789062, 33911: -620.2490234375, 41776: 620.1875, 25867: -620.17822265625, 21606: -620.1229248046875, 11233: -619.3797607421875, 16029: -619.2060546875, 5270: -617.795166015625, 7030: -616.967041015625, 44510: -616.3250732421875, 11797: -615.406982421875, 21938: 614.404541015625, 3051: -612.7914428710938, 18299: -611.7005004882812, 27840: -610.8372802734375, 953: -610.8170166015625, 3108: -609.8464965820312, 30386: -608.4761962890625, 52917: -608.4697875976562, 33029: -608.1091918945312, 13144: -607.8641357421875, 24780: 607.5514526367188, 57040: -605.8976440429688, 38804: -605.86083984375, 17966: -605.3199462890625, 15076: -605.0114135742188, 14548: -604.85595703125, 11104: -604.6380615234375, 26849: -604.4454345703125, 48045: -603.0465087890625, 54084: -602.5728149414062, 55312: -600.9103393554688, 51940: -598.700439453125, 35794: -596.997314453125, 17820: 595.8760986328125, 37658: 595.4979858398438, 12814: -595.48828125, 20868: -595.3732299804688, 42434: -594.8088989257812, 38772: -594.2882080078125, 24512: -593.6605834960938, 54008: -593.081298828125, 43065: -592.7459716796875, 45043: -591.8545532226562, 5086: -590.6098022460938, 55926: -589.267822265625, 9141: -588.4943237304688, 40636: 587.9340209960938, 13670: -587.8763427734375, 9561: -585.7297973632812, 40691: 584.9033813476562, 48666: -583.7749633789062, 37991: 582.9136962890625, 35914: -582.6162719726562, 39301: -582.3198852539062, 53514: -581.8631591796875, 57856: -581.0977783203125, 19280: -580.4785766601562, 4632: -578.8316650390625, 42140: -577.323974609375, 26324: -577.1810913085938, 11708: -576.7978515625, 26662: -576.5866088867188, 42083: -576.1944580078125, 16096: 575.4705200195312, 17810: -573.7857666015625, 34716: 573.19775390625, 26419: -573.1279907226562, 21420: 573.0166015625, 57660: -572.9967041015625, 7794: -572.892578125, 53547: 570.3462524414062, 33421: -569.6466064453125, 35582: 568.4592895507812, 43677: -567.900146484375, 22488: -567.657470703125, 16208: 567.3683471679688, 15022: -567.16845703125, 40752: -566.7745971679688, 13190: 566.7448120117188, 29757: -566.1732177734375, 54797: -565.4158325195312, 27640: -564.59814453125, 14107: -564.1410522460938, 47925: 562.8756713867188, 29476: -562.55126953125, 7422: -562.0504150390625, 50312: -560.2703247070312, 4276: -560.0955200195312, 20902: -558.6502075195312, 24770: 558.2863159179688, 3332: -557.2479248046875, 45712: -556.9354248046875, 57612: -556.511474609375, 41267: 555.7366943359375, 31667: 553.7757568359375, 19465: -553.201416015625, 54739: -552.4105834960938, 52664: -552.1051025390625, 41299: 550.8668823242188, 28734: 550.8324584960938, 15443: -550.4102783203125, 1722: -550.3378295898438, 14431: -550.2652587890625, 41494: -550.0260620117188, 52828: -548.4487915039062, 16366: -547.7406005859375, 50417: -545.617919921875, 47720: 544.0468139648438, 48485: 543.194580078125, 11296: -542.9143676757812, 16462: -542.8473510742188, 42117: -542.4957275390625, 28137: -541.283203125, 5660: -541.220947265625, 8795: -541.2062377929688, 57336: -540.8021240234375, 43599: -540.6775512695312, 36048: -538.8056640625, 37652: -537.8394775390625, 17574: -537.79541015625, 23119: -537.3009033203125, 48163: -536.9742431640625, 42114: -536.0147094726562, 4373: 534.9757690429688, 33009: -533.7542114257812, 47329: -533.4664306640625, 43672: -533.447998046875, 10260: -532.8551025390625, 59778: -532.7449340820312, 32730: 531.1136474609375, 20492: -530.6407470703125, 27248: -530.2244262695312, 19536: -530.0210571289062, 11244: -529.96923828125, 40020: -528.6492919921875, 1007: -528.09130859375, 37169: -527.6625366210938, 18244: 527.345458984375, 8055: -525.9782104492188, 39982: -525.5361328125, 29823: 525.2373046875, 3491: -523.80810546875, 21278: -523.4533081054688, 59815: -523.1781616210938}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of a negatively influential example\n",
        "\n",
        "image, label = get_item(27838)\n",
        "y_pred = model(image.view(-1, 28*28))\n",
        "_, predicted = torch.max(y_pred.data, 1)\n",
        "\n",
        "# z_test\n",
        "z_test = image.view(-1, 28*28)\n",
        "z_test_label = torch.tensor([train_dataset[27838][1]])\n",
        "\n",
        "print(\"predicted value: \", predicted)\n",
        "print(\"actual value: \", z_test_label)\n",
        "show_image(27838)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "CqwEA6XX_4Su",
        "outputId": "c8d70e19-6c61-4373-cc5e-61f31bcec2d0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted value:  tensor([8])\n",
            "actual value:  tensor([3])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of a positively influential example\n",
        "\n",
        "image, label = get_item(4866)\n",
        "y_pred = model(image.view(-1, 28*28))\n",
        "_, predicted = torch.max(y_pred.data, 1)\n",
        "\n",
        "# z_test\n",
        "z_test = image.view(-1, 28*28)\n",
        "z_test_label = torch.tensor([train_dataset[4866][1]])\n",
        "\n",
        "print(\"predicted value: \", predicted)\n",
        "print(\"actual value: \", z_test_label)\n",
        "show_image(4866)"
      ],
      "metadata": {
        "id": "3EwrTHMWAK6N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "outputId": "9b46374d-130d-4f10-9b4a-de49004284db"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted value:  tensor([7])\n",
            "actual value:  tensor([3])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a training function\n",
        "def train(model, epochs, training_loader, testing_loader, optimizer):\n",
        "  losses = []\n",
        "  accuracies = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "      for i, (images, labels) in enumerate(training_loader):\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(images.view(-1, 28*28))\n",
        "          loss = loss_fn(outputs, labels)\n",
        "\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      losses.append(loss.item())\n",
        "\n",
        "      correct = 0\n",
        "      for images, labels in testing_loader:\n",
        "          outputs = model(images.view(-1, 28*28))\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          correct += (predicted == labels).sum()\n",
        "      accuracy = 100 * (correct.item()) / len(test_dataset)\n",
        "      accuracies.append(accuracy)\n",
        "      print('Epoch: {}. Loss: {}. Accuracy: {}'.format(epoch, loss.item(), accuracy))"
      ],
      "metadata": {
        "id": "YzPypTe74uPZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_element_from_dataset(dataset, remove_index):\n",
        "    # Get the list of all indices except the one to be removed\n",
        "    indices = list(range(len(dataset)))\n",
        "    indices.pop(remove_index)\n",
        "\n",
        "    # Create a new dataset as a subset using the remaining indices\n",
        "    new_dataset = Subset(dataset, indices)\n",
        "\n",
        "    return new_dataset"
      ],
      "metadata": {
        "id": "FI1NrbjB6FTl"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def leave_one_out_retrain(z_test, z_test_label, old_model=model, top_influential=top_influential_dict):\n",
        "  # compute old test loss\n",
        "  old_loss = loss_fn(old_model(z_test), z_test_label)\n",
        "\n",
        "  change_in_test_loss = []\n",
        "  old_model.eval()\n",
        "  count = 0\n",
        "  for idx, val in top_influential.items():\n",
        "    new_train_dataset = remove_element_from_dataset(train_dataset, remove_index=idx)\n",
        "    new_train_loader = DataLoader(dataset=new_train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    new_model = LRModel(n_inputs, n_outputs)\n",
        "    count += 1\n",
        "    print(\"Retraining model #\", count)\n",
        "    optimizer = optim.SGD(new_model.parameters(), lr=0.001)\n",
        "    train(model=new_model, epochs=10, training_loader=train_loader, testing_loader=test_loader, optimizer=optimizer)\n",
        "    new_loss = loss_fn(new_model(z_test), z_test_label)\n",
        "    change_in_test_loss.append(new_loss - old_loss)\n",
        "\n",
        "  return change_in_test_loss"
      ],
      "metadata": {
        "id": "dHqBBIwf5GFV"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "image, label = get_item(3476, dataset='test')\n",
        "y_pred = model(image.view(-1, 28*28))\n",
        "_, predicted = torch.max(y_pred.data, 1)\n",
        "\n",
        "# z_test\n",
        "z_test = image.view(-1, 28*28)\n",
        "z_test_label = torch.tensor([test_dataset[3476][1]])"
      ],
      "metadata": {
        "id": "ZGqZ3FD28FQO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "change_in_test_loss = leave_one_out_retrain(z_test, z_test_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "s365kiYQ8YtV",
        "outputId": "41e5e6a4-8b77-4a73-e2d4-4e7385699236"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retraining model # 1\n",
            "Epoch: 0. Loss: 2.2016775608062744. Accuracy: 57.49\n",
            "Epoch: 1. Loss: 2.1185696125030518. Accuracy: 72.59\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-3f6049d74405>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchange_in_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleave_one_out_retrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_test_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-26-3a222f0226cf>\u001b[0m in \u001b[0;36mleave_one_out_retrain\u001b[0;34m(z_test, z_test_label, old_model, top_influential)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retraining model #\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mnew_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_test_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mchange_in_test_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_loss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mold_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-a7bc95c2b8ac>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, training_loader, testing_loader, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m           \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AH0ciTmv8t4b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
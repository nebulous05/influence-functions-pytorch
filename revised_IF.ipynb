{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYwr3RSxTlJPaBztVA0cbO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nebulous05/influence-functions-pytorch/blob/main/revised_IF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dwWAkMBW6HE8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "from torch.autograd import grad\n",
        "from torch.utils.data import Subset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "fssVKZ1ZoFYk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mnist_dataset(path):\n",
        "    from torchvision import datasets, transforms\n",
        "\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,)),\n",
        "        ],\n",
        "    )\n",
        "    dataset_train = datasets.MNIST(path, train=True, download=True, transform=transform)\n",
        "    dataset_test = datasets.MNIST(path, train=False, download=True, transform=transform)\n",
        "\n",
        "    return dataset_train, dataset_test\n",
        "\n",
        "training_set, dataset_test = create_mnist_dataset('./data')\n",
        "dataset_train, dataset_val = random_split(training_set, [55000, 5000])"
      ],
      "metadata": {
        "id": "CtiR3K-36mBr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9163c27b-ecb5-4517-f228-2f05627b55cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 53438461.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 2610739.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 12758723.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 1826162.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegressionMnist(nn.Module):\n",
        "    \"\"\"A simple logistic regression model for MNIST dataset.\"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        super(LogisticRegressionMnist, self).__init__()\n",
        "        self.linear = nn.Linear(28 * 28, 10, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.shape[0], -1)  # Flatten the image\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "J1483aJD7auT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(dataset_train, batch_size=16, shuffle=False)\n",
        "test_loader = DataLoader(dataset_test, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "0CBZ3X9g7vFS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epochs, lr, train_loader):\n",
        "    ''' returns a trained mnist_lr model '''\n",
        "    # set seeds to make the training process more deterministic\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "    random.seed(42)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = LogisticRegressionMnist()\n",
        "train(model, 5, 0.01, train_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmFLh6x48j6R",
        "outputId": "1b6ca9b7-2950-46ba-8679-bfea34016703"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 0.37933207960683396\n",
            "Epoch 2/5, Loss: 0.3129427697018673\n",
            "Epoch 3/5, Loss: 0.30474815194653765\n",
            "Epoch 4/5, Loss: 0.3014292686927355\n",
            "Epoch 5/5, Loss: 0.2998003072856799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# some functions to retrieve/view data\n",
        "def get_item(index, dataset='train'):\n",
        "    ''' returns a pair (image_tensor, label_int) '''\n",
        "    if dataset == 'train':\n",
        "        return dataset_train[index]\n",
        "    elif dataset == 'test':\n",
        "        return dataset_test[index]\n",
        "\n",
        "def show_image(index, dataset='train'):\n",
        "    ''' show an image with matplotlib '''\n",
        "    if dataset == 'train':\n",
        "        img = dataset_train[index][0].numpy().reshape(28, 28)\n",
        "    elif dataset == 'test':\n",
        "        img = dataset_test[index][0].numpy().reshape(28, 28)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CTWRFGNqAKqu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find all misclassified test points\n",
        "def find_misclassified_indices(model, dataset_test=dataset_test):\n",
        "  ''' returns a list of indices of all incorrectly labeled test points '''\n",
        "  model.eval()\n",
        "  indices = []\n",
        "  for i in range(len(dataset_test)):\n",
        "    image, label = get_item(i, dataset='test')\n",
        "    with torch.no_grad():\n",
        "      outputs = model(image)\n",
        "      _, predicted = torch.max(outputs, 1)\n",
        "      if predicted != label:\n",
        "        indices.append(i)\n",
        "  return indices\n",
        "\n",
        "misclassified_indices = find_misclassified_indices(model)\n",
        "print(random.choice(misclassified_indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOAcos66BKF-",
        "outputId": "4de41271-91c4-451d-ffc1-4a67d6ea7127"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_test = dataset_test[7850][0]\n",
        "z_test_label = dataset_test[7850][1]\n",
        "\n",
        "outputs = model(z_test)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "print(\"predicted:\", predicted)\n",
        "print(\"label:\", z_test_label)\n",
        "show_image(7850, dataset='test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "0v5qMzEkCI9j",
        "outputId": "e5475e60-1a76-4c0c-c6fb-79b31a3eae45"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted: tensor([8])\n",
            "label: 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_z(model, z, z_label):\n",
        "  '''\n",
        "  returns a list of two tensors, representing the\n",
        "  gradient of the loss function wrt params\n",
        "  '''\n",
        "  model.eval()\n",
        "  outputs = model(z)\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  loss = loss_fn(outputs, torch.tensor([z_label], dtype=torch.long))\n",
        "  params = [p for p in model.parameters() if p.requires_grad]\n",
        "  return list(grad(loss, params, create_graph=True))\n",
        "\n",
        "def hvp(y, w, v):\n",
        "    '''\n",
        "    goal: given our current estimate (v), compute the Hessian\n",
        "          vector product to act as our current unbiased estimator\n",
        "    '''\n",
        "    # First backprop: Compute the gradient of y with respect to w\n",
        "    first_grads = grad(y, w, retain_graph=True, create_graph=True)\n",
        "\n",
        "    # Elementwise products\n",
        "    elemwise_products = 0\n",
        "    for grad_elem, v_elem in zip(first_grads, v):\n",
        "        elemwise_products += torch.sum(grad_elem * v_elem)\n",
        "\n",
        "    # Second backprop: Compute gradient of elementwise product with respect to w\n",
        "    return_grads = grad(elemwise_products, w, create_graph=True)\n",
        "\n",
        "    return return_grads\n",
        "\n",
        "def s_test(z_test, z_test_label, train_dataset, model=model, num_repeats=10, damp=0.11, scale=25,\n",
        "           batch_size=1, recursion_depth=5000):\n",
        "  '''\n",
        "  goal: precompute s_test = H^{-1} v, where H is the Hessian of the loss function\n",
        "        and v is the gradient of the loss of the test point\n",
        "  '''\n",
        "  v = grad_z(model, z_test, z_test_label)\n",
        "  s_test = None\n",
        "\n",
        "  for _ in range(num_repeats):\n",
        "    h_estimate = [_v.detach().clone() for _v in v]\n",
        "    for i in range(recursion_depth):\n",
        "      # sample a random item from the training set\n",
        "      batch_indices = random.sample(range(len(train_dataset)), batch_size)\n",
        "      train_batch = [train_dataset[i] for i in batch_indices]\n",
        "      train_batch_inputs = torch.stack([x[0].squeeze() for x in train_batch])\n",
        "      train_batch_labels = torch.tensor([x[1] for x in train_batch])\n",
        "\n",
        "      model.eval()\n",
        "      model.zero_grad()\n",
        "      output = model(train_batch_inputs)\n",
        "      loss = nn.CrossEntropyLoss()(output, train_batch_labels)\n",
        "\n",
        "      hv = hvp(loss, list(model.parameters()), h_estimate)\n",
        "\n",
        "      h_estimate = [\n",
        "          _v + (1 - damp) * _h_e - _hv / scale\n",
        "          for _v, _h_e, _hv in zip(v, h_estimate, hv)\n",
        "      ]\n",
        "\n",
        "      # Detach from the current computation graph\n",
        "      h_estimate = [h.detach() for h in h_estimate]\n",
        "\n",
        "      if i%1000 == 0:\n",
        "        print(\"Completed \", i, \" iterations\")\n",
        "\n",
        "    if s_test is None:\n",
        "      s_test = h_estimate\n",
        "    else:\n",
        "      s_test = [s + h for s, h in zip(s_test, h_estimate)]\n",
        "\n",
        "  # Average over the number of samples\n",
        "  s_test = [s / num_repeats for s in s_test]\n",
        "  return s_test\n",
        "\n",
        "\n",
        "# gradient = grad_z(model, z_test, z_test_label)\n",
        "s_test = s_test(z_test, z_test_label, dataset_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivPH0VKrxG3K",
        "outputId": "cee7ecf9-0843-4158-9135-63267f066a48"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n",
            "Completed  0  iterations\n",
            "Completed  1000  iterations\n",
            "Completed  2000  iterations\n",
            "Completed  3000  iterations\n",
            "Completed  4000  iterations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# returns a list where the ith index is the value of the influence for index i\n",
        "# of the training set\n",
        "def compute_influence(model, train_dataset, s_test):\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    model.eval()\n",
        "\n",
        "    # List to store influence scores for each training point\n",
        "    influence_scores = []\n",
        "\n",
        "    # Loop over each data point in the training set\n",
        "    for z in train_dataset:\n",
        "        # Extract input and label from training dataset point\n",
        "        z_input = z[0]\n",
        "        z_label = torch.tensor([z[1]])\n",
        "\n",
        "        # Compute the gradient of the loss of the training point wrt the model parameters (v)\n",
        "        v = grad_z(model, z_input, z_label)\n",
        "\n",
        "        # Now compute the dot product between s_test and v\n",
        "        influence = 0\n",
        "        for s, v_i in zip(s_test, v):\n",
        "            influence += torch.sum(s * v_i)\n",
        "\n",
        "        # Store the negative of the influence as we want -s_test . v\n",
        "        influence_scores.append(-influence.item())  # Append scalar value to the list\n",
        "\n",
        "    return influence_scores\n",
        "\n",
        "influence_scores = compute_influence(model, dataset_train, s_test)"
      ],
      "metadata": {
        "id": "LUvSeUyeEtKu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def select_top_influential_points(influence_scores, top_n=500):\n",
        "    # Create a dictionary mapping index i to the influence score\n",
        "    influence_dict = {i: influence_scores[i] for i in range(len(influence_scores))}\n",
        "\n",
        "    # Sort the dictionary by the absolute value of the influence scores in descending order\n",
        "    sorted_influences = sorted(influence_dict.items(), key=lambda item: abs(item[1]), reverse=True)\n",
        "\n",
        "    # Select the top N most influential points\n",
        "    top_influential_dict = dict(sorted_influences[:top_n])\n",
        "\n",
        "    return top_influential_dict\n",
        "\n",
        "top_influential_dict = select_top_influential_points(influence_scores, 100)\n",
        "print(top_influential_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTtSxfZ_FdKJ",
        "outputId": "75ae0cfd-a2c8-4c99-cf80-6b64a856f237"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{22849: -14997.21484375, 22513: -14190.7490234375, 44398: -13772.8974609375, 41529: -13654.677734375, 51113: -13090.447265625, 25567: -12135.265625, 16399: -11757.5439453125, 8834: -11737.080078125, 6619: -11732.830078125, 959: -11247.6474609375, 27538: -10995.5576171875, 34721: -10822.8037109375, 35093: -10803.611328125, 44016: -10452.6474609375, 1483: -10369.9228515625, 17417: -10221.259765625, 19036: -9962.462890625, 28158: -9853.9228515625, 26964: -9853.3193359375, 50327: -9577.736328125, 35703: -9552.3125, 6589: -9480.912109375, 1316: -9330.5322265625, 25069: 9312.9658203125, 12145: -9133.6865234375, 34700: -9089.4296875, 40404: -8854.5478515625, 3689: -8746.6982421875, 45009: -8745.7548828125, 42906: -8634.4541015625, 50050: 8629.291015625, 7170: -8628.3095703125, 25666: -8568.751953125, 28874: -8528.9345703125, 27119: -8487.7919921875, 39287: 8450.447265625, 30185: -8338.478515625, 4718: 8290.4658203125, 23076: 8272.6611328125, 32057: -8222.99609375, 40302: -8151.01513671875, 11538: 8148.837890625, 31009: 8106.1337890625, 47270: -8071.6826171875, 15629: 8053.9677734375, 43622: -7998.71240234375, 27018: 7983.62890625, 50044: 7895.7802734375, 37427: 7868.40771484375, 7012: 7854.767578125, 5055: 7804.1484375, 27191: -7786.65966796875, 31848: 7741.271484375, 52300: 7730.23095703125, 18221: -7684.810546875, 39559: 7667.3173828125, 48300: -7591.11767578125, 13094: 7552.0908203125, 10626: -7506.1865234375, 40913: -7443.97216796875, 43901: -7417.732421875, 6053: -7413.2919921875, 16394: -7389.86865234375, 34153: -7389.2783203125, 34268: -7368.6728515625, 39630: -7349.3642578125, 1579: -7322.76953125, 13435: -7284.49169921875, 32882: 7283.43994140625, 34928: -7262.9755859375, 47898: -7224.7236328125, 38256: -7195.48876953125, 8589: -7179.00927734375, 25313: 7149.5654296875, 3738: 7136.87841796875, 22694: 7102.349609375, 9531: -7096.16796875, 50494: 7091.537109375, 42537: -7085.30078125, 25856: 7050.7197265625, 49108: 7018.390625, 19573: -7013.849609375, 48634: -6997.93798828125, 27854: 6988.82275390625, 24306: -6988.0830078125, 22167: -6967.61181640625, 19758: -6965.869140625, 38530: -6946.60986328125, 11498: 6935.9775390625, 47438: -6916.7890625, 13951: -6912.7783203125, 46644: -6901.80615234375, 2604: -6893.494140625, 33901: 6876.32763671875, 44240: 6852.9423828125, 3076: -6817.12158203125, 6264: 6801.80908203125, 39140: -6797.67626953125, 27314: 6782.42626953125, 19236: -6777.89208984375}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(25069, dataset='train')\n",
        "print(dataset_train[25069][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "fdJ1E5phc9qY",
        "outputId": "db1b1bef-b324-4b53-a0e6-192f0287edde"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model_state_dict.pth')"
      ],
      "metadata": {
        "id": "zgdX2xYpsA4w"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_element_from_dataset(dataset, remove_index):\n",
        "    # Get the list of all indices except the one to be removed\n",
        "    indices = list(range(len(dataset)))\n",
        "    indices.pop(remove_index)\n",
        "\n",
        "    # Create a new dataset as a subset using the remaining indices\n",
        "    new_dataset = Subset(dataset, indices)\n",
        "\n",
        "    return new_dataset\n",
        "\n",
        "def leave_one_out_retrain(z_test, z_test_label, old_model, top_influential=top_influential_dict):\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  # compute old test loss\n",
        "  old_model.eval()\n",
        "  with torch.no_grad():\n",
        "    old_loss = loss_fn(old_model(z_test), torch.tensor([z_test_label], dtype=torch.long))\n",
        "  print(\"Old test loss: \", old_loss.item())\n",
        "\n",
        "  change_in_test_loss = []\n",
        "\n",
        "  count = 0\n",
        "  for idx, val in top_influential.items():\n",
        "    new_train_dataset = remove_element_from_dataset(dataset_train, remove_index=idx)\n",
        "    new_train_loader = DataLoader(dataset=new_train_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    count += 1\n",
        "    print(\"Retraining model #\", count, \" (idx=\", idx, \")\")\n",
        "\n",
        "    torch.manual_seed(42)\n",
        "    new_model = LogisticRegressionMnist()\n",
        "    new_model.load_state_dict(torch.load('model_state_dict.pth'))\n",
        "    train(new_model, 9, 0.01, new_train_loader) # ~30k steps\n",
        "\n",
        "    with torch.no_grad():\n",
        "      new_loss = loss_fn(new_model(z_test), torch.tensor([z_test_label], dtype=torch.long))\n",
        "    change_in_test_loss.append(new_loss.item() - old_loss.item())\n",
        "    print()\n",
        "    print(\"Change in test loss: \", change_in_test_loss[-1])\n",
        "    print()\n",
        "\n",
        "  return change_in_test_loss"
      ],
      "metadata": {
        "id": "miRa5xUhaoon"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "change_in_test_loss = leave_one_out_retrain(z_test, z_test_label, model)\n",
        "# print(change_in_test_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "S35kEST7bFid",
        "outputId": "84c67d04-b039-4f0d-e79e-7cb85916c579"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Old test loss:  5.6112260818481445\n",
            "Retraining model # 1  (idx= 22849 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-66c159660f2d>:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  new_model.load_state_dict(torch.load('model_state_dict.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9, Loss: 0.29882249437541275\n",
            "Epoch 2/9, Loss: 0.2983287484301097\n",
            "Epoch 3/9, Loss: 0.298038080387758\n",
            "Epoch 4/9, Loss: 0.2978622298205511\n",
            "Epoch 5/9, Loss: 0.2977539240444917\n",
            "Epoch 6/9, Loss: 0.29768627547778714\n",
            "Epoch 7/9, Loss: 0.29764353630683965\n",
            "Epoch 8/9, Loss: 0.2976162602465086\n",
            "Epoch 9/9, Loss: 0.2975987336555536\n",
            "\n",
            "Change in test loss:  0.04441213607788086\n",
            "\n",
            "Retraining model # 2  (idx= 22513 )\n",
            "Epoch 1/9, Loss: 0.29888889365875576\n",
            "Epoch 2/9, Loss: 0.29839714185387295\n",
            "Epoch 3/9, Loss: 0.29810679822709407\n",
            "Epoch 4/9, Loss: 0.29793113572040814\n",
            "Epoch 5/9, Loss: 0.29782296759100796\n",
            "Epoch 6/9, Loss: 0.29775540094384884\n",
            "Epoch 7/9, Loss: 0.2977127139876451\n",
            "Epoch 8/9, Loss: 0.2976854883704319\n",
            "Epoch 9/9, Loss: 0.2976679779034392\n",
            "\n",
            "Change in test loss:  0.026731014251708984\n",
            "\n",
            "Retraining model # 3  (idx= 44398 )\n",
            "Epoch 1/9, Loss: 0.2988666357459536\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-8b0088f812a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchange_in_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleave_one_out_retrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_test_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(change_in_test_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-66c159660f2d>\u001b[0m in \u001b[0;36mleave_one_out_retrain\u001b[0;34m(z_test, z_test_label, old_model, top_influential)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mnew_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegressionMnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mnew_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_state_dict.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_train_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# ~30k steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-464b7fa6d0ee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, lr, train_loader)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# see torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"little\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"I;16B\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m                 \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                 \u001b[0mnew\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mMemoryError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecursionError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m             \u001b[0mbytes_consumed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def leave_one_out_retrain_single(z_test, z_test_label, old_model, idx):\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  # compute old test loss\n",
        "  old_model.eval()\n",
        "  with torch.no_grad():\n",
        "    old_loss = loss_fn(old_model(z_test), torch.tensor([z_test_label], dtype=torch.long))\n",
        "  print(\"Old test loss: \", old_loss.item())\n",
        "\n",
        "  change_in_test_loss = []\n",
        "\n",
        "  count = 0\n",
        "\n",
        "  new_train_dataset = remove_element_from_dataset(dataset_train, remove_index=idx)\n",
        "  new_train_loader = DataLoader(dataset=new_train_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "  count += 1\n",
        "  print(\"Retraining model #\", count, \" (idx=\", idx, \")\")\n",
        "\n",
        "  torch.manual_seed(42)\n",
        "  new_model = LogisticRegressionMnist()\n",
        "  new_model.load_state_dict(torch.load('model_state_dict.pth'))\n",
        "  train(new_model, 9, 0.01, new_train_loader) # ~30k steps\n",
        "\n",
        "  with torch.no_grad():\n",
        "    new_loss = loss_fn(new_model(z_test), torch.tensor([z_test_label], dtype=torch.long))\n",
        "  change_in_test_loss.append(new_loss.item() - old_loss.item())\n",
        "  print()\n",
        "  print(\"Change in test loss: \", change_in_test_loss[-1])\n",
        "  print()\n",
        "\n",
        "  return change_in_test_loss"
      ],
      "metadata": {
        "id": "G8Q26QaaX3vt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leave_one_out_retrain_single(z_test, z_test_label, model, 25069)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NocUQVmYAR4",
        "outputId": "e8605ecb-665c-4ae3-d50b-515ae251304a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Old test loss:  5.6112260818481445\n",
            "Retraining model # 1  (idx= 25069 )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-982c1776fdc4>:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  new_model.load_state_dict(torch.load('model_state_dict.pth'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9, Loss: 0.29882508051679746\n",
            "Epoch 2/9, Loss: 0.2983280457810885\n",
            "Epoch 3/9, Loss: 0.2980363943709961\n",
            "Epoch 4/9, Loss: 0.2978601876701542\n",
            "Epoch 5/9, Loss: 0.297751729473593\n",
            "Epoch 6/9, Loss: 0.2976839892266057\n",
            "Epoch 7/9, Loss: 0.2976411914977355\n",
            "Epoch 8/9, Loss: 0.29761388727126253\n",
            "Epoch 9/9, Loss: 0.2975963288549726\n",
            "\n",
            "Change in test loss:  0.009134769439697266\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.009134769439697266]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot scatter plot between actual diff in loss and predicted diff in loss\n",
        "actual_diff_in_loss = [x.item() for x in change_in_test_loss]\n",
        "predicted_diff_in_loss = [(-1/len(dataset_train))* x for x in top_influential_dict.values()]\n",
        "\n",
        "\n",
        "plt.scatter(actual_diff_in_loss, predicted_diff_in_loss)\n",
        "\n",
        "# plot a line of best fit\n",
        "m, b = np.polyfit(actual_diff_in_loss, predicted_diff_in_loss, 1)\n",
        "plt.plot(actual_diff_in_loss, m*np.array(actual_diff_in_loss) + b, color='gray')\n",
        "plt.xlabel(\"Actual diff in loss\")\n",
        "plt.ylabel(\"Predicted diff in loss\")"
      ],
      "metadata": {
        "id": "f71X3rmijzSn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}